{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Model / Ensemble Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code performs item-filtering using KNNBasic algorithm from the surprise package in Python.\n",
    "\n",
    "First, necessary packages including pandas, surprise, reader, accuracy and train_test_split are imported. The beer_df.csv dataset is loaded into a pandas dataframe called beer_df using pd.read_csv function. The dataset contains information on beer reviews including the brewery name, beer name, review time, reviewer's name, location, ratings for aroma, taste, appearance and overall rating. The dataset is loaded into a Pandas DataFrame and displays the first 5 rows of the data.\n",
    "\n",
    "The content-filtering is then performed four times, using each of the features reviewed within the dataset. These include: \n",
    "- review_aroma\n",
    "- review_appearance\n",
    "- review_palate\n",
    "- review_taste\n",
    "\n",
    "In each case, a reader object is created and KNNBasic model is instantiated with the cosine similarity matrix and the algorithm set to not use user-based recommendation. Then, the dataset is split into train and test sets with a 75% training and 25% testing ratio. The KNNBasic model is then fit on the training data and used to make predictions on the test data.\n",
    "\n",
    "The accuracy of each model is computed using mean squared error (MSE) and mean absolute error (MAE) using the accuracy module from surprise package. Finally, the MAE value is printed as output in each case.\n",
    "\n",
    "Each feature is run through and then combined using an Ensemble Model. Which is then comparing the reviews of it's predicted value to the actual with each user input. \n",
    "\n",
    "#### Perform a Content-Based Model using the only feature that is not a review: ABV\n",
    "\n",
    "A final Content-Based Model is run with the ABV feature. This feature is clearly the more accurate model, with the lowest MSE and MAE values. These results are then compared to the Ensemble Model, which is the combination of all four review features. The Ensemble Model has a slightly higher MSE and MAE value than the ABV model, but is still a very accurate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all columns \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>key</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>phones</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>province</th>\n",
       "      <th>websites</th>\n",
       "      <th>index</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_profilename</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "      <th>review_year</th>\n",
       "      <th>review_month</th>\n",
       "      <th>beer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010 Williams St</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/sanleandro/2010williamsst</td>\n",
       "      <td>37.711807</td>\n",
       "      <td>-122.177658</td>\n",
       "      <td>21st Amendment Brewery</td>\n",
       "      <td>5105952111</td>\n",
       "      <td>94577</td>\n",
       "      <td>CA</td>\n",
       "      <td>http://21st-amendment.com</td>\n",
       "      <td>1495017</td>\n",
       "      <td>735</td>\n",
       "      <td>2011-03-01 00:49:43</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>illidurit</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21 Rock</td>\n",
       "      <td>9.7</td>\n",
       "      <td>66190</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010 Williams St</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/sanleandro/2010williamsst</td>\n",
       "      <td>37.711807</td>\n",
       "      <td>-122.177658</td>\n",
       "      <td>21st Amendment Brewery</td>\n",
       "      <td>5105952111</td>\n",
       "      <td>94577</td>\n",
       "      <td>CA</td>\n",
       "      <td>http://21st-amendment.com</td>\n",
       "      <td>1495350</td>\n",
       "      <td>735</td>\n",
       "      <td>2008-12-04 19:03:15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>magictrokini</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Harvest Moon</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45648</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010 Williams St</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/sanleandro/2010williamsst</td>\n",
       "      <td>37.711807</td>\n",
       "      <td>-122.177658</td>\n",
       "      <td>21st Amendment Brewery</td>\n",
       "      <td>5105952111</td>\n",
       "      <td>94577</td>\n",
       "      <td>CA</td>\n",
       "      <td>http://21st-amendment.com</td>\n",
       "      <td>1495733</td>\n",
       "      <td>735</td>\n",
       "      <td>2010-01-23 20:55:46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>HapWifeHapLife</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21st Amendment IPA</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20781</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010 Williams St</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/sanleandro/2010williamsst</td>\n",
       "      <td>37.711807</td>\n",
       "      <td>-122.177658</td>\n",
       "      <td>21st Amendment Brewery</td>\n",
       "      <td>5105952111</td>\n",
       "      <td>94577</td>\n",
       "      <td>CA</td>\n",
       "      <td>http://21st-amendment.com</td>\n",
       "      <td>1501253</td>\n",
       "      <td>735</td>\n",
       "      <td>2010-04-08 18:58:54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>pwoody11</td>\n",
       "      <td>Belgian Strong Dark Ale</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Monk's Blood</td>\n",
       "      <td>8.3</td>\n",
       "      <td>52510</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010 Williams St</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>San Leandro</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/sanleandro/2010williamsst</td>\n",
       "      <td>37.711807</td>\n",
       "      <td>-122.177658</td>\n",
       "      <td>21st Amendment Brewery</td>\n",
       "      <td>5105952111</td>\n",
       "      <td>94577</td>\n",
       "      <td>CA</td>\n",
       "      <td>http://21st-amendment.com</td>\n",
       "      <td>1501262</td>\n",
       "      <td>735</td>\n",
       "      <td>2010-03-14 16:30:10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>metter98</td>\n",
       "      <td>Belgian Strong Dark Ale</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Monk's Blood</td>\n",
       "      <td>8.3</td>\n",
       "      <td>52510</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>Ale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            address categories         city country  \\\n",
       "0  2010 Williams St    Brewery  San Leandro      US   \n",
       "1  2010 Williams St    Brewery  San Leandro      US   \n",
       "2  2010 Williams St    Brewery  San Leandro      US   \n",
       "3  2010 Williams St    Brewery  San Leandro      US   \n",
       "4  2010 Williams St    Brewery  San Leandro      US   \n",
       "\n",
       "                               key        lat        long  \\\n",
       "0  us/ca/sanleandro/2010williamsst  37.711807 -122.177658   \n",
       "1  us/ca/sanleandro/2010williamsst  37.711807 -122.177658   \n",
       "2  us/ca/sanleandro/2010williamsst  37.711807 -122.177658   \n",
       "3  us/ca/sanleandro/2010williamsst  37.711807 -122.177658   \n",
       "4  us/ca/sanleandro/2010williamsst  37.711807 -122.177658   \n",
       "\n",
       "             brewery_name      phones  postalCode province  \\\n",
       "0  21st Amendment Brewery  5105952111       94577       CA   \n",
       "1  21st Amendment Brewery  5105952111       94577       CA   \n",
       "2  21st Amendment Brewery  5105952111       94577       CA   \n",
       "3  21st Amendment Brewery  5105952111       94577       CA   \n",
       "4  21st Amendment Brewery  5105952111       94577       CA   \n",
       "\n",
       "                    websites    index  brewery_id          review_time  \\\n",
       "0  http://21st-amendment.com  1495017         735  2011-03-01 00:49:43   \n",
       "1  http://21st-amendment.com  1495350         735  2008-12-04 19:03:15   \n",
       "2  http://21st-amendment.com  1495733         735  2010-01-23 20:55:46   \n",
       "3  http://21st-amendment.com  1501253         735  2010-04-08 18:58:54   \n",
       "4  http://21st-amendment.com  1501262         735  2010-03-14 16:30:10   \n",
       "\n",
       "   review_overall  review_aroma  review_appearance review_profilename  \\\n",
       "0             3.5           3.5                4.0          illidurit   \n",
       "1             4.0           4.0                4.0       magictrokini   \n",
       "2             4.0           4.0                3.5     HapWifeHapLife   \n",
       "3             4.0           3.5                4.5           pwoody11   \n",
       "4             4.0           3.5                4.0           metter98   \n",
       "\n",
       "                       beer_style  review_palate  review_taste  \\\n",
       "0  American Double / Imperial IPA            3.5           3.5   \n",
       "1                    American IPA            3.0           4.0   \n",
       "2                    American IPA            4.0           4.0   \n",
       "3         Belgian Strong Dark Ale            4.0           4.0   \n",
       "4         Belgian Strong Dark Ale            4.0           4.5   \n",
       "\n",
       "            beer_name  beer_abv  beer_beerid  review_year  review_month  \\\n",
       "0             21 Rock       9.7        66190         2011             3   \n",
       "1        Harvest Moon       6.4        45648         2008            12   \n",
       "2  21st Amendment IPA       7.0        20781         2010             1   \n",
       "3        Monk's Blood       8.3        52510         2010             4   \n",
       "4        Monk's Blood       8.3        52510         2010             3   \n",
       "\n",
       "  beer_type  \n",
       "0       IPA  \n",
       "1       IPA  \n",
       "2       IPA  \n",
       "3       Ale  \n",
       "4       Ale  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open beer_df.csv\n",
    "beer_df = pd.read_csv('data/beer_df.csv', low_memory=False)\n",
    "beer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.3400\n",
      "MAE:  0.4379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43794879510767576"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running a model with KNNBasic and review_aroma as the only feature\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'review_aroma']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "aroma_model = KNNBasic(sim_options=sim_options)\n",
    "aroma_model.fit(trainset)\n",
    "predictions = aroma_model.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.2586\n",
      "MAE:  0.3762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37624881747586375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running a model with KNNBasic and review_appearance as the only feature\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'review_appearance']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "appear_model = KNNBasic(sim_options=sim_options)\n",
    "appear_model.fit(trainset)\n",
    "predictions = appear_model.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above performed the best with this feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.3290\n",
      "MAE:  0.4238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42378508291252387"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running a model with KNNBasic and review_palate as the only feature\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'review_palate']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "palate_model = KNNBasic(sim_options=sim_options)\n",
    "palate_model.fit(trainset)\n",
    "predictions = palate_model.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.3935\n",
      "MAE:  0.4630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4630291374952523"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running a model with KNNBasic and review_taste as the only feature\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'review_taste']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "taste_model = KNNBasic(sim_options=sim_options)\n",
    "taste_model.fit(trainset)\n",
    "predictions = taste_model.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all models with features into one as a hybrid model\n",
    "def hybrid_model(username, beer):\n",
    "    # Get predictions from all four models\n",
    "    aroma_prediction = aroma_model.predict(username, beer).est\n",
    "    appear_prediction = appear_model.predict(username, beer).est\n",
    "    palate_prediction = palate_model.predict(username, beer).est\n",
    "    taste_prediction = taste_model.predict(username, beer).est\n",
    "\n",
    "    prediction = (aroma_prediction * 0.25) + (appear_prediction * 0.25) + (palate_prediction * 0.25) + (taste_prediction * 0.25)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating: 3.6825320512820516\n",
      "Actual rating: 3.75\n"
     ]
    }
   ],
   "source": [
    "# Get a prediction using the hybrid model\n",
    "username = \"magictrokini\"\n",
    "beer = \"Harvest Moon\"\n",
    "prediction = hybrid_model(username, beer)\n",
    "mask = (beer_df['review_profilename'] == username) & (beer_df['beer_name'] == beer)\n",
    "row = beer_df.loc[mask]\n",
    "\n",
    "actual_rating = row[['review_aroma', 'review_appearance', 'review_palate', 'review_taste']].mean(axis=1).values[0]\n",
    "\n",
    "print(\"Predicted rating:\", prediction)\n",
    "print(\"Actual rating:\", actual_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between predicted & actual ratings: 0.29888816024696263\n"
     ]
    }
   ],
   "source": [
    "# Create prediction vs actual average\n",
    "differences = []\n",
    "\n",
    "# Loop through each row in beer_df\n",
    "for index, row in beer_df.iterrows():\n",
    "    username = row['review_profilename']\n",
    "    beer = row['beer_name']\n",
    "    prediction = hybrid_model(username, beer)\n",
    "    actual_rating = row[['review_aroma', 'review_appearance', 'review_palate', 'review_taste']].mean()\n",
    "    difference = abs(prediction - actual_rating)\n",
    "    differences.append(difference)\n",
    "\n",
    "avg_difference = sum(differences) / len(differences)\n",
    "\n",
    "print(\"Average difference between predicted & actual ratings:\", avg_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Content-Based Model with beer_abv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABV - Alcohol by Volume. \n",
    "\n",
    "Such metric shows the amount of alcohol within the beer. Many of the reviews rated the taste of high ABV beers lower than those with low ABV, as the taste of alcohol in a beer can make it distasteful to many. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of column for ABV Range metrics chosen as follows:\n",
    "- 1 (Low ABV) is 0-4.9%\n",
    "- 2 (Medium ABV) is 5-9.9%\n",
    "- 3 (High ABV) is 10-14.9%\n",
    "- 4 (Very High ABV) is 15-20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column of abv ranges with 0-4.9 being 1, 5-9.9 being 2, 10-14.9 being 3, 15-20 being 4\n",
    "beer_df['abv_range'] = pd.cut(beer_df['beer_abv'], bins=[0, 4.9, 9.9, 14.9, 20], labels=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    128481\n",
       "3     19995\n",
       "1     11924\n",
       "4        51\n",
       "Name: abv_range, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_df['abv_range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3913\n",
      "MAE:  0.4821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48214050871012004"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running a model with NormalPredictor \n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "abv_base = NormalPredictor()\n",
    "abv_base.fit(trainset)\n",
    "predictions = abv_base.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0071\n",
      "MAE:  0.0394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03943791220605567"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running a model with SVD\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "svd_abv = SVD()\n",
    "svd_abv.fit(trainset)\n",
    "predictions = svd_abv.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.2051\n",
      "MAE:  0.2698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2698296324626393"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running a model with KNNBasic\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "knn_abv = KNNBasic(sim_options=sim_options)\n",
    "knn_abv.fit(trainset)\n",
    "predictions = knn_abv.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 50, 'n_epochs': 60, 'lr_all': 0.005, 'reg_all': 0.4}\n",
      "0.020928627430998076\n",
      "{'n_factors': 50, 'n_epochs': 60, 'lr_all': 0.002, 'reg_all': 0.4}\n",
      "0.08005447047484245\n"
     ]
    }
   ],
   "source": [
    "# Perform a grid search to find the best parameters for SVD\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "param_grid = {'n_factors': [50, 100, 150], 'n_epochs': [20, 40, 60], 'lr_all': [0.002, 0.005, 0.008], 'reg_all': [0.4, 0.6, 0.8]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['mse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# Print the best parameters\n",
    "print(gs.best_params['mse'])\n",
    "print(gs.best_score['mse'])\n",
    "print(gs.best_params['mae'])\n",
    "print(gs.best_score['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0202\n",
      "MAE:  0.0794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07939609423479072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "svd_abv = SVD(n_factors= 50, n_epochs= 60, lr_all= 0.005, reg_all= 0.4)\n",
    "svd_abv.fit(trainset)\n",
    "predictions = svd_abv.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 150, 'n_epochs': 60, 'lr_all': 0.005, 'reg_all': 0.4}\n",
      "0.021104234959296003\n",
      "{'n_factors': 50, 'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.4}\n",
      "0.0803066887301323\n"
     ]
    }
   ],
   "source": [
    "# Perform a randomizedsearch to find the best parameters for SVD\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import RandomizedSearchCV\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "param_grid = {'n_factors': [50, 100, 150], 'n_epochs': [20, 40, 60], 'lr_all': [0.002, 0.005, 0.008], 'reg_all': [0.4, 0.6, 0.8]}\n",
    "rs = RandomizedSearchCV(SVD, param_grid, measures=['mse', 'mae'], cv=3)\n",
    "\n",
    "rs.fit(data)\n",
    "\n",
    "# Print the best parameters\n",
    "print(rs.best_params['mse'])\n",
    "print(rs.best_score['mse'])\n",
    "print(rs.best_params['mae'])\n",
    "print(rs.best_score['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0214\n",
      "MAE:  0.0789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07885782254676313"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(beer_df[['review_profilename', 'beer_name', 'abv_range']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "svd_abv = SVD(n_factors= 50, n_epochs= 20, lr_all= 0.005, reg_all= 0.4)\n",
    "svd_abv.fit(trainset)\n",
    "predictions = svd_abv.test(testset)\n",
    "\n",
    "accuracy.mse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the models with parameters, there is not much of a difference in the accuracy of the model. The model with the lowest MAE is the one with the default parameters running the SVD algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1480  0.1481  0.1468  0.1469  0.1477  0.1475  0.0005  \n",
      "MAE (testset)     0.0794  0.0794  0.0787  0.0798  0.0796  0.0794  0.0004  \n",
      "Fit time          3.81    3.80    3.81    3.75    3.77    3.79    0.03    \n",
      "Test time         0.27    0.12    0.12    0.26    0.12    0.18    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.1479974 , 0.14812268, 0.14681074, 0.14691884, 0.14772733]),\n",
       " 'test_mae': array([0.07935502, 0.07935863, 0.07865643, 0.07979161, 0.07960887]),\n",
       " 'fit_time': (3.8133859634399414,\n",
       "  3.798312187194824,\n",
       "  3.814105987548828,\n",
       "  3.752117872238159,\n",
       "  3.767116069793701),\n",
       " 'test_time': (0.26619410514831543,\n",
       "  0.11992502212524414,\n",
       "  0.11975288391113281,\n",
       "  0.263962984085083,\n",
       "  0.12062907218933105)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing a last check to see if the model is overfitting by perfomring a cross validation\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "cross_validate(svd_abv, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
